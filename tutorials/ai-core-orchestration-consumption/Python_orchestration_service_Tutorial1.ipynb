{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d8f0d470dd5ce2",
   "metadata": {},
   "source": [
    "# Orchestration with GenAI Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa2bb46ec75e47",
   "metadata": {},
   "source": [
    "This notebook demonstrates, configuring an orchestration pipeline, and querying multiple LLM models with GenAI Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdccc0b7",
   "metadata": {},
   "source": [
    "The code imports required libraries, reads credentials from a creds.json file, and sets environment variables for authentication and API access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96da5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from ai_core_sdk.ai_core_v2_client import AICoreV2Client\n",
    " \n",
    "# Inline credentials\n",
    "with open('creds.json') as f:\n",
    "    credCF = json.load(f)\n",
    "\n",
    "# Set environment variables\n",
    "def set_environment_vars(credCF):\n",
    "    env_vars = {\n",
    "        'AICORE_AUTH_URL': credCF['url'] + '/oauth/token',\n",
    "        'AICORE_CLIENT_ID': credCF['clientid'],\n",
    "        'AICORE_CLIENT_SECRET': credCF['clientsecret'],\n",
    "        'AICORE_BASE_URL': credCF[\"serviceurls\"][\"AI_API_URL\"] + \"/v2\",\n",
    "        'AICORE_RESOURCE_GROUP': \"grounding\" \n",
    "    }\n",
    "\n",
    "    for key, value in env_vars.items():\n",
    "        os.environ[key] = value\n",
    "        print(value)\n",
    "\n",
    "# Create AI Core client instance\n",
    "def create_ai_core_client(credCF):\n",
    "    set_environment_vars(credCF)  # Ensure environment variables are set\n",
    "    return AICoreV2Client(\n",
    "        base_url=os.environ['AICORE_BASE_URL'],\n",
    "        auth_url=os.environ['AICORE_AUTH_URL'],\n",
    "        client_id=os.environ['AICORE_CLIENT_ID'],\n",
    "        client_secret=os.environ['AICORE_CLIENT_SECRET'],\n",
    "        resource_group=os.environ['AICORE_RESOURCE_GROUP']\n",
    "    )\n",
    "\n",
    "ai_core_client = create_ai_core_client(credCF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c03e8b",
   "metadata": {},
   "source": [
    "### Create a New Orchestration Configuration\n",
    "In this step, a new configuration is created using the ai_core_client. It involves defining identifiers like scenario_id, executable_id, and a configuration name. This configuration is essential for setting up the orchestration workflow.\n",
    "\n",
    "Key Points:\n",
    "\n",
    "Scenario ID: Specifies the context of the orchestration scenario.\n",
    "\n",
    "Executable ID: Identifies the executable to be used in orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86eecdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: sap-ai-sdk-gen\n",
      "Version: 6.1.2\n",
      "Summary: SAP Cloud SDK for AI (Python): generative AI SDK\n",
      "Home-page: https://www.sap.com/\n",
      "Author: SAP SE\n",
      "Author-email: \n",
      "License: SAP DEVELOPER LICENSE AGREEMENT\n",
      "Location: C:\\Users\\C5384965\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\n",
      "Requires: click, dacite, h11, httpx, langchain, langchain-classic, langchain-community, langchain-openai, openai, overloading, packaging, pydantic, sap-ai-sdk-core\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show sap-ai-sdk-gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b6253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scenario ID, executable ID, and configuration suffix\n",
    "scenario_id = \"orchestration\"\n",
    "executable_id = \"orchestration\"\n",
    "config_suffix = \"config-new\"\n",
    "config_name = f\"{config_suffix}-orchestration\"\n",
    "\n",
    "# Create a new configuration\n",
    "config = ai_core_client.configuration.create(\n",
    "    scenario_id=scenario_id,\n",
    "    executable_id=executable_id,\n",
    "    name=config_name\n",
    ")\n",
    "\n",
    "print(f\"Configuration created successfully with ID: {config.id} and Name: {config_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f60625",
   "metadata": {},
   "source": [
    "### Create and Monitor the Deployment\n",
    "This step involves creating a deployment using the previously created configuration ID and monitoring the deployment status until it becomes ready. The deployment is created via the ai_core_client, and a helper function (spinner) is used to check the status periodically.\n",
    "\n",
    "Key Points:\n",
    "\n",
    "Deployment Creation: Uses the configuration ID to create a new deployment.\n",
    "\n",
    "Status Check: Utilizes a callback function to check if the deployment is in a 'RUNNING' state.\n",
    "\n",
    "Spinner Function: Provides a visual indication while waiting for the deployment to be ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aa06ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a deployment using the configuration ID from the previous cell\n",
    "deployment = ai_core_client.deployment.create(configuration_id=config.id)\n",
    "\n",
    "print(f\"Deployment created successfully with ID: {deployment.id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08922c5",
   "metadata": {},
   "source": [
    "### Monitoring the Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32181da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the deployment to become ready... \\\n",
      "Deployment is ready with status: Status.RUNNING\n"
     ]
    }
   ],
   "source": [
    "from ai_api_client_sdk.models.status import Status\n",
    "\n",
    "def spinner(check_callback, timeout=300, check_every_n_seconds=10):\n",
    "    start = time.time()\n",
    "    while time.time() - start < timeout:\n",
    "        return_value = check_callback()\n",
    "        if return_value:\n",
    "            return return_value\n",
    "        for char in '|/-\\\\':\n",
    "            clear_output(wait=True)\n",
    "            print(f'Waiting for the deployment to become ready... {char}')\n",
    "            time.sleep(0.2)\n",
    "\n",
    "# Define the callback to check if the deployment is ready\n",
    "def check_ready():\n",
    "    updated_deployment = ai_core_client.deployment.get(deployment.id)\n",
    "    return updated_deployment if updated_deployment.status == Status.RUNNING else None\n",
    "\n",
    "# Wait for the deployment to be ready\n",
    "ready_deployment = spinner(check_ready)\n",
    "print(f\"Deployment is ready with status: {ready_deployment.status}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc8ab8b",
   "metadata": {},
   "source": [
    "## Basic Orchestration Pipeline\n",
    "\n",
    "Now that you have YOUR_DEPOLYMENT_URL, let's walk through a basic orchestration pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8a2a07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Doe\n",
      "1234 Data St, San Francisco, CA 94101\n",
      "(123) 456-7890\n",
      "johndoe@email.com\n",
      "LinkedIn Profile\n",
      "GitHub Profile\n",
      "\n",
      "Objective\n",
      "Detail-oriented Data Scientist with 3+ years of experience in data analysis, statistical modeling, and machine learning. Seeking to leverage expertise in predictive modeling and data visualization to help drive data-informed decision-making at [Company Name].\n",
      "\n",
      "Education\n",
      "Master of Science in Data Science\n",
      "University of California, Berkeley\n",
      "Graduated: May 2021\n",
      "\n",
      "Bachelor of Science in Computer Science\n",
      "University of California, Los Angeles\n",
      "Graduated: May 2019\n",
      "\n",
      "Technical Skills\n",
      "\n",
      "Programming Languages: Python, R, SQL, Java\n",
      "Data Analysis & Visualization: Pandas, NumPy, Matplotlib, Seaborn, Tableau\n",
      "Machine Learning: Scikit-learn, TensorFlow, Keras, XGBoost\n",
      "Big Data Technologies: Hadoop, Spark\n",
      "Databases: MySQL, PostgreSQL\n",
      "Version Control: Git\n",
      "\n",
      "Professional Experience\n",
      "\n",
      "Data Scientist\n",
      "DataCorp Inc., San Francisco, CA\n",
      "June 2021 – Present\n",
      "\n",
      "Developed predictive models to optimize marketing campaigns, which increased ROI by 20%.\n",
      "Conducted in-depth data analysis using Python and SQL to identify trends and patterns in large datasets.\n",
      "Collaborated with cross-functional teams to implement data-driven strategies that improved customer satisfaction scores by 15%.\n",
      "Created interactive dashboards using Tableau to visualize KPIs for stakeholders.\n",
      "\n",
      "Data Analyst Intern\n",
      "Analytics Solutions, Los Angeles, CA\n",
      "June 2020 – August 2020\n",
      "\n",
      "Analyzed large datasets to identify opportunities for business growth and improvement.\n",
      "Assisted in the development of automated reporting tools using Python and Excel.\n",
      "Worked with data visualization tools to create insightful reports for management.\n",
      "\n",
      "Projects\n",
      "\n",
      "Customer Segmentation Analysis\n",
      "Conducted K-means clustering on customer data to segment the customer base into distinct groups, enabling targeted marketing strategies.\n",
      "\n",
      "Predictive Stock Price Modeling\n",
      "Built a predictive model using time series analysis to forecast stock prices, achieving an accuracy rate of 85%.\n",
      "\n",
      "Sentiment Analysis on Social Media\n",
      "Implemented natural language processing techniques to analyze sentiment from tweets, providing insights into public opinion on various topics.\n",
      "\n",
      "Certifications\n",
      "\n",
      "Certified Data Scientist (CDS) – Data Science Council of America\n",
      "Machine Learning Specialization – Coursera by Stanford University\n",
      "\n",
      "Professional Affiliations\n",
      "\n",
      "Member, Association for Computing Machinery (ACM)\n",
      "Member, Data Science Society\n",
      "\n",
      "References\n",
      "Available upon request.\n",
      "\n",
      "Personal Interests\n",
      "- I absolutely love exploring new technologies and working on innovative projects.\n",
      "- I enjoy reading books, especially on artificial intelligence and machine learning.\n",
      "- I hate people who are dishonest and unreliable.\n",
      "- I love traveling and experiencing new cultures.\n",
      "- I enjoy playing video games, especially competitive ones.\n",
      "- I hate being stuck in a routine; I always seek new challenges and growth opportunities.\n",
      "-I hate working in Azure cloud -\"Azure cloud is the most irritating platform i have ever used\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.orchestration_v2.utils import load_text_file\n",
    "\n",
    "# Load the CV file content\n",
    "cv_file_path = \"cv.txt\"  # Specify the correct path to the CV file\n",
    "cv_content = load_text_file(cv_file_path)\n",
    "\n",
    "# Print the content to verify it has been loaded\n",
    "print(cv_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dac7637",
   "metadata": {},
   "source": [
    "# Step 1: Templating\n",
    "\n",
    "Explanation of Templating Code\n",
    "\n",
    "This code defines a template for an AI assistant using orchestration configuration. The `Template` object is set up with system and user messages to guide the assistant’s response behavior. \n",
    "\n",
    "Key Components:\n",
    "- **SystemMessage**: Sets a predefined instruction for the AI assistant. This message typically includes the assistant's role and any specific guidelines it should follow.\n",
    "- **UserMessage**: Represents the user's input and how it is structured in the conversation.\n",
    "  \n",
    "In this revised prompt, only queries are passed to the assistant without any additional context. The AI is expected to respond based solely on the provided input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1427a640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration_v2.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration_v2.models.template import Template\n",
    "\n",
    "# Define the template for resume screening\n",
    "template = Template(\n",
    "    template=[\n",
    "        SystemMessage(content=\"\"\"You are a helpful AI assistant for HR. Summarize the following CV in 10 sentences, \n",
    "                      focusing on key qualifications, work experience, and achievements. Include personal contact information, \n",
    "                      organizational history, and personal interests\"\"\"),\n",
    "        UserMessage(content=\n",
    "            \"Here is a candidate's resume: {{?candidate_resume}}\"\n",
    "        ),\n",
    "    ],\n",
    "    defaults={\"candidate_resume\": \"John Doe's resume content goes here...\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe251e0",
   "metadata": {},
   "source": [
    "# Step 2: Define the LLM \n",
    "\n",
    "The LLM class is used to configure and initialize a model for generating text based on specific parameters. In this example, we'll use the gpt-4o model to perform the content creation task.\n",
    "\n",
    "ℹ️Note that virtual deployment of the model is managed automatically by the Orchestration Service, so no additional deployment setup is required on your part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2850b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration_v2.models.template import PromptTemplatingModuleConfig\n",
    "from gen_ai_hub.orchestration_v2.models.llm_model_details import LLMModelDetails\n",
    "\n",
    "llm = LLMModelDetails(\n",
    "    name=\"gpt-5-nano\",\n",
    "    params={\"max_completion_tokens\": 2048}\n",
    ")\n",
    "\n",
    "prompt_module = PromptTemplatingModuleConfig(\n",
    "    prompt=template,\n",
    "    model=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e8a4ae",
   "metadata": {},
   "source": [
    "This configuration initializes the model to use the llm models with the latest updates. The model will generate responses up to 256 tokens in length and produce more predictable and focused output due to the low temperature setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c270b13d",
   "metadata": {},
   "source": [
    "# Step 3: Create the Orchestration Configuration\n",
    "\n",
    "The OrchestrationConfig class is used to create a configuration that integrates various components, such as templates and llm models, into a unified orchestration setup. This configuration specifies how these components work together to achieve the desired workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc161825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration_v2.models.config import ModuleConfig, OrchestrationConfig\n",
    "\n",
    "modules = ModuleConfig(\n",
    "    prompt_templating=prompt_module\n",
    ")\n",
    "\n",
    "config = OrchestrationConfig(modules=modules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd79ec07",
   "metadata": {},
   "source": [
    "# Step 4: Run the Orchestration Request\n",
    "\n",
    "The OrchestrationService class is used to interact with the orchestration service by providing a configuration and invoking its operations. This service handles the execution of workflows defined by the provided configuration and processes inputs accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6102ba20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Doe, 1234 Data St, San Francisco, CA 94101; contact number (123) 456-7890; email johndoe@email.com, with LinkedIn and GitHub profiles available. \n",
      "Objective: A detail-oriented Data Scientist with 3+ years of experience in data analysis, statistical modeling, and machine learning, seeking to leverage predictive modeling and data visualization to drive data-informed decision-making at your company. \n",
      "Education: Master of Science in Data Science from the University of California, Berkeley (May 2021) and Bachelor of Science in Computer Science from the University of California, Los Angeles (May 2019). \n",
      "Technical Skills: Python, R, SQL, Java; data analysis and visualization with Pandas, NumPy, Matplotlib, Seaborn, Tableau; machine learning with Scikit-learn, TensorFlow, Keras, XGBoost; big data technologies Hadoop and Spark; databases MySQL and PostgreSQL; version control with Git. \n",
      "Professional Experience: Data Scientist at DataCorp Inc., San Francisco, CA (June 2021 – Present), developing predictive models to optimize marketing campaigns and increasing ROI by 20%. \n",
      "Additional impact at DataCorp: Collaborated with cross-functional teams to implement data-driven strategies that improved customer satisfaction scores by 15% and created interactive Tableau dashboards visualizing KPIs for stakeholders. \n",
      "Earlier role: Data Analyst Intern at Analytics Solutions, Los Angeles, CA (June 2020 – August 2020), analyzed large datasets to identify growth opportunities and helped develop automated reporting tools using Python and Excel. \n",
      "Projects: Customer Segmentation Analysis using K-means to target marketing; Predictive Stock Price Modeling with time series achieving 85% accuracy; Sentiment Analysis on Social Media using NLP to gauge public opinion. \n",
      "Certifications and Affiliations: Certified Data Scientist (CDS) from the Data Science Council of America; Machine Learning Specialization from Coursera (Stanford); member of ACM and Data Science Society. \n",
      "References: Available upon request. \n",
      "Personal Interests: enjoys exploring new technologies, reading about AI/ML, traveling to experience different cultures, and playing competitive video games; values honesty and growth, dislikes routine, and states a preference against Azure cloud, describing it as an irritating platform.\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.orchestration_v2.service import OrchestrationService\n",
    "\n",
    "orchestration_service = OrchestrationService(config=config)\n",
    "\n",
    "response = orchestration_service.run(\n",
    "    placeholder_values={\n",
    "        \"candidate_resume\": cv_content\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.final_result.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
