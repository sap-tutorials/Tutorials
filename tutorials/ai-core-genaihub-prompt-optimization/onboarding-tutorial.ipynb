{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b73af-0100-471b-81e0-4d9fbddc6de3",
   "metadata": {
    "id": "9c7b73af-0100-471b-81e0-4d9fbddc6de3"
   },
   "outputs": [],
   "source": [
    "# Loading the credentials from the env file\n",
    "from gen_ai_hub.proxy.gen_ai_hub_proxy import GenAIHubProxyClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Fetching environment variables\n",
    "AICORE_BASE_URL = os.getenv(\"AICORE_BASE_URL\")\n",
    "AICORE_RESOURCE_GROUP = os.getenv(\"AICORE_RESOURCE_GROUP\")\n",
    "AICORE_AUTH_URL = os.getenv(\"AICORE_AUTH_URL\")\n",
    "AICORE_CLIENT_ID = os.getenv(\"AICORE_CLIENT_ID\")\n",
    "AICORE_CLIENT_SECRET = os.getenv(\"AICORE_CLIENT_SECRET\")\n",
    "\n",
    "# Initializing the GenAIHubProxyClient\n",
    "client = GenAIHubProxyClient(\n",
    "    base_url=AICORE_BASE_URL,\n",
    "    auth_url=AICORE_AUTH_URL,\n",
    "    client_id=AICORE_CLIENT_ID,\n",
    "    client_secret=AICORE_CLIENT_SECRET,\n",
    "    resource_group=AICORE_RESOURCE_GROUP\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Pd3wsKls4OS5",
   "metadata": {
    "id": "Pd3wsKls4OS5"
   },
   "source": [
    "# Dependencies and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j7YWZOg103r0",
   "metadata": {
    "id": "j7YWZOg103r0"
   },
   "outputs": [],
   "source": [
    "!pip install rich PyYAML \"sap-ai-sdk-gen[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03050198-427c-4157-9c06-eeda4aa2a47f",
   "metadata": {
    "id": "03050198-427c-4157-9c06-eeda4aa2a47f"
   },
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy import get_proxy_client\n",
    "import pathlib\n",
    "import yaml\n",
    "\n",
    "from ai_api_client_sdk.models.input_artifact_binding import InputArtifactBinding\n",
    "from ai_api_client_sdk.models.parameter_binding import ParameterBinding\n",
    "from ai_api_client_sdk.models.artifact import Artifact\n",
    "from ai_api_client_sdk.models.label import Label\n",
    "\n",
    "SUPPORTED_MODELS = [\n",
    "    'gemini-2.5-pro:001',\n",
    "    'gpt-4o:2024-08-06'\n",
    "]\n",
    "\n",
    "SUPPORTED_METRICS = [\"LLMaaJ:Sem_Sim_1\", \"JSON_Match\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e39b20",
   "metadata": {
    "id": "f6e39b20"
   },
   "outputs": [],
   "source": [
    "client = get_proxy_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ea323c6",
   "metadata": {
    "id": "6ea323c6"
   },
   "outputs": [],
   "source": [
    "from logging import PlaceHolder\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "\n",
    "class PromptTemplate(BaseModel):\n",
    "    role: str\n",
    "    content: str\n",
    "\n",
    "\n",
    "class PromptTemplateSpec(BaseModel):\n",
    "    template: List[PromptTemplate]\n",
    "\n",
    "\n",
    "    @property\n",
    "    def placeholders(self):\n",
    "        placeholders = set()\n",
    "        pattern = re.compile(r'\\{\\{\\s*\\?\\s*(\\w+)\\s*\\}\\}')\n",
    "        for message in self.template:\n",
    "            placeholders.update(pattern.findall(message.content))\n",
    "        return placeholders\n",
    "\n",
    "    @classmethod\n",
    "    def from_optimizer_result(cls, input_):\n",
    "        placeholders = input_[\"user_message_template_fields\"]\n",
    "        def replace(msg):\n",
    "            for key in placeholders:\n",
    "                msg = msg.replace(\"{\"+key+\"}\", \"{{?\"+ key + \"}}\")\n",
    "            return msg\n",
    "\n",
    "        return cls(\n",
    "            template=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": replace(input_[\"system_prompt\"]),\n",
    "                },{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": replace(input_[\"user_message_template\"]),\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def escape_curly_brackets(self) -> \"PromptTemplateSpec\":\n",
    "        # 1. Hide each {{?key}} placeholder with a unique token\n",
    "        placeholder_pattern = re.compile(r'\\{\\{\\s*\\?\\s*(\\w+)\\s*\\}\\}')\n",
    "        mapping = {}\n",
    "        counter = 1\n",
    "\n",
    "        def _hide(match):\n",
    "            nonlocal counter\n",
    "            token = f\"__PLACEHOLDER_{counter}__\"\n",
    "            mapping[token] = match.group(0)\n",
    "            counter += 1\n",
    "            return token\n",
    "\n",
    "        new_templates = []\n",
    "        for msg in self.template:\n",
    "            # a) hide custom placeholders\n",
    "            hidden = placeholder_pattern.sub(_hide, msg.content)\n",
    "            # b) escape all remaining braces\n",
    "            escaped = hidden.replace('{', '{{').replace('}', '}}')\n",
    "            # c) restore the original placeholders\n",
    "            print(mapping)\n",
    "            for token, original in mapping.items():\n",
    "                escaped = escaped.replace(token, original)\n",
    "\n",
    "            new_templates.append(PromptTemplate(role=msg.role, content=escaped))\n",
    "\n",
    "        # return a fresh copy\n",
    "        return PromptTemplateSpec(template=new_templates)\n",
    "\n",
    "\n",
    "\n",
    "def fetch_prompt_template(prompt_template: str) -> PromptTemplateSpec:\n",
    "    headers = {\n",
    "        **client.request_header,\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    url = f\"{client.ai_core_client.base_url}/lm/promptTemplates\"\n",
    "    scenario, sep, name = prompt_template.partition(\"/\")\n",
    "    if sep:\n",
    "        name, sep, version = name.partition(\":\")\n",
    "    if sep:\n",
    "        body = {\"name\": name,\n",
    "                \"version\": version,\n",
    "                \"scenario\": scenario,\n",
    "                \"includeSpec\": True\n",
    "            }\n",
    "        response =  requests.get(url, headers=headers, params=body)\n",
    "        response.raise_for_status()\n",
    "        response = response.json()\n",
    "        if response[\"count\"] > 0:\n",
    "            response = response[\"resources\"][0]\n",
    "        else:\n",
    "            raise ValueError(f\"Prompt template {name} not found.\")\n",
    "    else:\n",
    "        url += f\"/{prompt_template}\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        response = response.json()\n",
    "    return PromptTemplateSpec.model_validate(response[\"spec\"])\n",
    "\n",
    "def load_prompt_template(prompt: str | pathlib.Path | list | dict | PromptTemplateSpec) -> PromptTemplateSpec:\n",
    "    if isinstance(prompt, PromptTemplateSpec):\n",
    "        return prompt\n",
    "    if isinstance(prompt, (str, pathlib.Path)) and pathlib.Path(prompt).exists():\n",
    "        with open(prompt, \"r\") as f:\n",
    "            prompt = yaml.safe_load(f)\n",
    "    elif isinstance(prompt, str):\n",
    "        return fetch_prompt_template(prompt)\n",
    "    if isinstance(prompt, dict):\n",
    "        # expect dict with keys \"system\" [optional] and \"user\"\n",
    "        messages = []\n",
    "        if \"system\" in prompt:\n",
    "            messages.append({\"role\": \"system\", \"content\": prompt[\"system\"]})\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt[\"user\"]})\n",
    "        return PromptTemplateSpec(template=messages)\n",
    "    elif isinstance(prompt, list):\n",
    "        # expect list of dicts with keys \"role\" and \"content\"\n",
    "        return PromptTemplateSpec(template=messages)\n",
    "    else:\n",
    "        raise ValueError(\"Prompt must be a string, Path, list or dict\")\n",
    "\n",
    "\n",
    "def push_prompt_template(prompt_template: PromptTemplateSpec,\n",
    "                         prompt_template_name_registry: str,\n",
    "                         prompt_template_version: str,\n",
    "                         scenario: str,\n",
    "                         update=False):\n",
    "    headers = {\n",
    "        **client.request_header,\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    url = f\"{client.ai_core_client.base_url}/lm/promptTemplates\"\n",
    "    body = {\"name\": prompt_template_name_registry,\n",
    "            \"version\": prompt_template_version,\n",
    "            \"scenario\": scenario}\n",
    "    res = requests.get(url, headers=headers, params=body).json()\n",
    "    if res[\"count\"] > 0 and not update:\n",
    "        print(f\"Prompt template {prompt_template_name_registry} already exists. Use update=True to update.\")\n",
    "        return res[\"resources\"][0]\n",
    "    # Prepare body\n",
    "\n",
    "    body[\"spec\"] = prompt_template.model_dump()\n",
    "    # Prepare headers\n",
    "    response = requests.post(url, headers=headers, json=body)\n",
    "    # Handle response\n",
    "    if response.status_code == 201:\n",
    "        response = response.json()\n",
    "    elif response.status_code in (400, 409, 413):\n",
    "        # Return error details\n",
    "        raise requests.HTTPError(f\"Upload failed ({response.status_code}): {response.text}\")\n",
    "    else:\n",
    "        response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def convert_py_notation(template):\n",
    "    pattern = re.compile(r'\\{\\{\\s*\\?\\s*(\\w+)\\s*\\}\\}')\n",
    "    return pattern.sub(lambda match: \"{\" + match.group(1) + \"}\", template)\n",
    "\n",
    "\n",
    "def validate_prompt(prompt: PromptTemplateSpec):\n",
    "    values = {k: \"???\" for k in prompt.placeholders}\n",
    "\n",
    "    for message in prompt.template:\n",
    "        if message.role == \"user\":\n",
    "            try:\n",
    "                convert_py_notation(message.content).format(**values)\n",
    "            except KeyError as err:\n",
    "                msg = [\"Unexpected key error when running test formatting.\"]\n",
    "                msg += [\"This is most likeyly due to unescaped curly brackets.\"]\n",
    "                msg += [\"You can try fixing this by running `prompt = prompt.escape_curly_brackets()` and use the new prompt template.\"]\n",
    "                raise ValueError(\"\\n\".join(msg)) from err\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.highlighter import RegexHighlighter\n",
    "from rich.theme import Theme\n",
    "from rich.panel import Panel\n",
    "from rich import print\n",
    "\n",
    "class TemplateHighlighter(RegexHighlighter):\n",
    "    \"\"\"Apply style to anything that looks like an email.\"\"\"\n",
    "\n",
    "    base_style = \"template.\"\n",
    "    highlights = [r\"(?P<placeholder>\\{\\{\\s*\\?[^\\{\\}\\s]+\\s*\\}\\})\"]\n",
    "\n",
    "highlighter = TemplateHighlighter()\n",
    "theme = Theme({\"template.placeholder\": \"bold magenta\", \"example.email\": \"bold magenta\"})\n",
    "console = Console(highlighter=highlighter, theme=theme)\n",
    "\n",
    "\n",
    "def print_prompt_template(prompt_template: PromptTemplateSpec | str | pathlib.Path, addition: str | None = None):\n",
    "\n",
    "    prompt_template = load_prompt_template(prompt_template)\n",
    "    addition = f' - {addition}' if addition else ''\n",
    "\n",
    "    for message in prompt_template.template:\n",
    "        if message.role == \"system\":\n",
    "            console.print(Panel(highlighter(message.content), title=\"System Message\" + addition, border_style=\"red\"))\n",
    "        elif message.role == \"user\":\n",
    "            console.print(Panel(highlighter(message.content), title=\"User Message\" + addition, border_style=\"green\"))\n",
    "        else:\n",
    "            console.print(Panel(highlighter(message.content), title=\"Assistant Message\" + addition))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "067c2cf6",
   "metadata": {
    "id": "067c2cf6"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import requests\n",
    "import mimetypes\n",
    "from urllib.parse import quote\n",
    "import pathlib\n",
    "import json\n",
    "\n",
    "\n",
    "def validate_dataset(dataset: str | pathlib.Path | list, expected_keys: None | List[str] = None) -> bool:\n",
    "    if isinstance(dataset, (str, pathlib.Path)):\n",
    "        with open(dataset, \"r\") as f:\n",
    "            try:\n",
    "                dataset = json.load(f)\n",
    "            except json.JSONDecodeError as e:\n",
    "                raise ValueError(f\"Invalid JSON in file: {e}\")\n",
    "    if not isinstance(dataset, list):\n",
    "        raise ValueError(\"Dataset must be a list of dictionaries.\")\n",
    "\n",
    "    def validate_item(item: dict, excepted_keys: None | List[str]) -> bool:\n",
    "        excepted_keys = set(excepted_keys) if excepted_keys else None\n",
    "        if set(item.keys()) != {\"fields\", \"answer\"}:\n",
    "            raise ValueError(\"Each item must contain 'fields' and 'answer' keys.\")\n",
    "        if not isinstance(item[\"fields\"], dict):\n",
    "            raise ValueError(\"'fields' must be a dictionary.\")\n",
    "        fields = set(item[\"fields\"].keys())\n",
    "        if excepted_keys is not None:\n",
    "            if fields != excepted_keys:\n",
    "                if fields.difference(excepted_keys):\n",
    "                    raise ValueError(f\"Unexpected keys in 'fields'. Expected: {excepted_keys}, Found: {fields}\")\n",
    "                if excepted_keys.difference(fields):\n",
    "                    raise ValueError(f\"Missing keys in 'fields'. Expected: {excepted_keys}, Found: {fields}\")\n",
    "        if not all([isinstance(k, str) for k in item[\"fields\"].values()]):\n",
    "            raise ValueError(\"All values in 'fields' must be strings.\")\n",
    "        return fields\n",
    "\n",
    "    excepted_keys = expected_keys\n",
    "    for i, item in enumerate(dataset):\n",
    "        if not isinstance(item, dict):\n",
    "            raise ValueError(\"Each item in the dataset must be a dictionary.\")\n",
    "        try:\n",
    "            excepted_keys = validate_item(item, excepted_keys)\n",
    "        except ValueError as e:\n",
    "            raise ValueError(f\"Error in entry {i}\") from e\n",
    "    return True\n",
    "\n",
    "\n",
    "def upload_dataset(secret: str,\n",
    "                   local_path: str | pathlib.Path,\n",
    "                   remote_path: str,\n",
    "                   scenario: str,\n",
    "                   description: str | None = None,\n",
    "                   overwrite: bool = False,\n",
    "                   expected_keys: None | List[str] = None,\n",
    "\n",
    "                   allow_bucket_root: bool = False) -> str:\n",
    "    # Validate dataset\n",
    "    validate_dataset(local_path, expected_keys)\n",
    "    # check if secret exists\n",
    "    secrets = [r.name for r in client.ai_core_client.object_store_secrets.query().resources]\n",
    "    if secret not in secrets:\n",
    "        raise ValueError(f\"Secret '{secret}' not found in object store secrets. Known secrets: {secrets}\")\n",
    "\n",
    "    # Check if local path exists\n",
    "    remote_path = remote_path.lstrip(\"/\")\n",
    "    if \"/\" not in remote_path and not allow_bucket_root:\n",
    "        raise ValueError(\n",
    "            \"Remote path must use subdirectories. Otherwise the whole bucket will be used as an input artifact. Set allow_bucket_root=True to allow this.\"\n",
    "        )\n",
    "\n",
    "    # URL-encode the path parameter\n",
    "    path = f\"{secret}/\" + remote_path.lstrip(\"/\")\n",
    "    encoded_path = quote(path, safe=\"\")\n",
    "    url = f\"{client.ai_core_client.base_url}/lm/dataset/files/{encoded_path}\"\n",
    "    params = {\"overwrite\": str(overwrite).lower()}\n",
    "\n",
    "    # Prepare headers\n",
    "    headers = {\n",
    "        **client.request_header,\n",
    "        \"Content-Type\": \"application/octet-stream\",\n",
    "    }\n",
    "    # Guess MIME type\n",
    "    guessed_type, _ = mimetypes.guess_type(local_path)\n",
    "    if guessed_type:\n",
    "        headers[\"Content-Type\"] = guessed_type\n",
    "\n",
    "    with open(local_path, \"rb\") as f:\n",
    "        response = requests.put(url, params=params, headers=headers, data=f)\n",
    "\n",
    "    # Handle response\n",
    "    if response.status_code == 201:\n",
    "        response = response.json()\n",
    "    elif response.status_code in (400, 409, 413):\n",
    "        # Return error details\n",
    "        raise requests.HTTPError(f\"Upload failed ({response.status_code}): {response.text}\")\n",
    "    else:\n",
    "        response.raise_for_status()\n",
    "    artifact_url = \"/\".join(response[\"url\"].split(\"/\")[:-1])\n",
    "    for artifact in client.ai_core_client.artifact.query().resources:\n",
    "        if response[\"url\"].startswith(artifact.url + \"/\"):\n",
    "            return artifact, response[\"url\"].removeprefix(artifact.url).lstrip(\"/\")\n",
    "\n",
    "    # Create new artifact\n",
    "    path = response[\"url\"].split(\"/\")[-1]\n",
    "    new_artifact = client.ai_core_client.artifact.create(\n",
    "        name=f\"{scenario}-prompt-optimization\",\n",
    "        kind=Artifact.Kind.DATASET,\n",
    "        url=artifact_url,\n",
    "        scenario_id=scenario,\n",
    "        description=\"Datasets for prompt optimization\" if description is None else description,\n",
    "        resource_group=headers[client.ai_core_client.rest_client.resource_group_header]\n",
    "    )\n",
    "    return new_artifact, path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eXT05z-77zuK",
   "metadata": {
    "id": "eXT05z-77zuK"
   },
   "source": [
    "## Create Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yCXzXl1C7zVL",
   "metadata": {
    "id": "yCXzXl1C7zVL"
   },
   "outputs": [],
   "source": [
    "old_new_name_mapping = {\n",
    "    \"gemini-2.5-pro:001\": \"gemini-2.5-pro:001\",\n",
    "    \"gpt-4o:2024-08-06\": \"openai/gpt-4o-2024-08-06\"\n",
    "}\n",
    "\n",
    "old_new_name_mapping.update({old_new_name_mapping[k]: k for k, v in old_new_name_mapping.items()})\n",
    "\n",
    "\n",
    "def create_config(metric: str,\n",
    "                  reference_model: str,\n",
    "                  targets: dict,\n",
    "                  dataset_path: str,\n",
    "                  scenario: str,\n",
    "                  prompt: PromptTemplateSpec) -> str:\n",
    "    assert metric in SUPPORTED_METRICS, f\"Unsupported metric: {metric}. Supported metrics: {SUPPORTED_METRICS}\"\n",
    "    assert reference_model in SUPPORTED_MODELS, f\"Unsupported reference model: {reference_model}. Supported models: {SUPPORTED_MODELS}\"\n",
    "    assert all(model in SUPPORTED_MODELS for model in targets.keys()), f\"Unsupported target models: {targets}. Supported models: {SUPPORTED_MODELS}\"\n",
    "    input_parameters = [\n",
    "        ParameterBinding(key=\"dataset\", value=dataset_path),\n",
    "        ParameterBinding(key=\"optimizationMetric\", value=metric),\n",
    "        ParameterBinding(key=\"basePrompt\", value=f'{scenario}/{prompt[\"name\"]}:{prompt[\"version\"]}'),\n",
    "        ParameterBinding(key=\"baseModel\", value=reference_model),\n",
    "        ParameterBinding(key=\"targetModels\", value=','.join(targets.keys())),\n",
    "        ParameterBinding(key=\"targetPromptMapping\", value=\",\".join([f\"{old_new_name_mapping[k]}={v}\" for k, v in targets.items()]))\n",
    "        \n",
    "        \n",
    "    ]\n",
    "    existing_configs = client.ai_core_client.configuration.query(scenario_id='genai-optimizations', executable_ids=['genai-optimizations'])\n",
    "    params = {par.key: par.value for par in input_parameters}\n",
    "    for conf in existing_configs.resources:\n",
    "        if {par.key: par.value for par in conf.parameter_bindings} == params:\n",
    "            return conf.id\n",
    "    \n",
    "    input_artifacts = [InputArtifactBinding(key=\"prompt-data\", artifact_id=artifact_id)]\n",
    "\n",
    "    response = client.ai_core_client.configuration.create(\n",
    "        name = \"prompt-optimization-config\", # custom name of configuration\n",
    "        scenario_id = \"genai-optimizations\", # value from workflow\n",
    "        executable_id = \"genai-optimizations\", # value from workflow\n",
    "        resource_group = resource_group,\n",
    "        parameter_bindings = input_parameters,\n",
    "        input_artifact_bindings = input_artifacts\n",
    "    )\n",
    "\n",
    "    return response.id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "M7NpyMM9NI7k",
   "metadata": {
    "id": "M7NpyMM9NI7k"
   },
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "\n",
    "def fetch_results(execution_id):\n",
    "    response = client.ai_core_client.execution.get(execution_id = execution_id)\n",
    "    if response.status.name not in {'DEAD', 'COMPLETED'}:\n",
    "        raise RuntimeError('Execution not finished!')\n",
    "    path = f\"default/{execution_id}/result-data/results.json\"\n",
    "    encoded_path = quote(path, safe=\"\")\n",
    "    url = f\"{client.ai_core_client.base_url}/lm/dataset/files/{encoded_path}\"\n",
    "    headers = {\n",
    "        **client.request_header,\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.json()# results = response.json()\n",
    "\n",
    "\n",
    "def print_result(result):\n",
    "    origin_model = result[\"origin_model\"]\n",
    "    table = Table(title=\"Performance\")\n",
    "    table.add_column(\"Model\", justify=\"right\", style=\"cyan\", no_wrap=True)\n",
    "    table.add_column(\"Pre Optimization\", style=\"magenta\")\n",
    "    table.add_column(\"Post Optimization\", justify=\"right\", style=\"green\")\n",
    "    table.add_row(origin_model[\"model_name\"], f'{origin_model[\"score\"]:.3f}', \"n/a - reference run\")\n",
    "    for m in result[\"target_models\"]:\n",
    "        table.add_row(m[\"model_name\"], f'{m[\"pre_optimization_score\"]:.3f}', f'{m[\"post_optimization_score\"]:.3f}')\n",
    "    console.print(table)\n",
    "    for m in result[\"target_models\"]:\n",
    "        print_prompt_template(PromptTemplateSpec.from_optimizer_result(m), addition=m['model_name'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QcrTeIvD8Rgz",
   "metadata": {
    "id": "QcrTeIvD8Rgz"
   },
   "source": [
    "### Download Demo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1BRIRT5a6phA",
   "metadata": {
    "id": "1BRIRT5a6phA"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "files = [\n",
    "    (\"default/example/base-prompt.yaml\", \"./facility_prompt.yaml\"),\n",
    "    (\"default/example/facility-train.json\", \"./facility-train.json\")\n",
    "]\n",
    "\n",
    "for remote, local in files:\n",
    "    local_path = pathlib.Path(local)\n",
    "    if not local_path.exists():\n",
    "        url = f\"{client.ai_core_client.base_url}/lm/dataset/files/{remote}\"\n",
    "        headers = {\n",
    "            **client.request_header,\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        with local_path.open(\"w\") as stream:\n",
    "            stream.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sDyiLKIM4ha_",
   "metadata": {
    "id": "sDyiLKIM4ha_"
   },
   "outputs": [],
   "source": [
    "resource_group = client.request_header[client.ai_core_client.rest_client.resource_group_header]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fY-fejJ14YLC",
   "metadata": {
    "id": "fY-fejJ14YLC"
   },
   "source": [
    "# Start Prompt Optimizer Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ExirmzxlEgYO",
   "metadata": {
    "id": "ExirmzxlEgYO"
   },
   "source": [
    "### Loading a Local Prompt Template\n",
    "\n",
    "**The prompt template is structured in a `system` and a `user` message. Placeholders in the prompt template have to be wrapped in `{{?key}}`.**\n",
    "\n",
    "\n",
    "Your prompt can be provided in any of the following forms and will be normalized to a `PromptTemplateSpec` under the hood:\n",
    "\n",
    "#### From Local Disk\n",
    "**A file path** (`str` or `Path`) pointing to a YAML or JSON file defining either:\n",
    "  - a **mapping** with keys  \n",
    "    - `\"user\"` (required) and  \n",
    "    - `\"system\"` (optional)\n",
    "\n",
    "```yaml\n",
    "system: |-\n",
    "    You are a helpful assistant\n",
    "assistant: |-\n",
    "    Write a poen on {{?topic}}\n",
    "```\n",
    "or  \n",
    "  - a **list** of message objects, each with `\"role\"` (e.g. `\"system\"` or `\"user\"`) and `\"content\"` (string)\n",
    "\n",
    "```yaml\n",
    "- role: system\n",
    "  content: |-\n",
    "    You are a helpful assistant\n",
    "- role: user\n",
    "  content: |-\n",
    "    Write a poen on {{?topic}}\n",
    "```\n",
    "\n",
    "\n",
    "#### Alternative: Prompt Registry\n",
    "- **A lookup string** of the form `\"<scenario>/<name>:<version>\"` (or just `\"<name>:<version>\"`) will be fetched from the AI-core prompt‐template API; if you omit the version, the latest will be returned.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mYsHaqTVFEQZ",
   "metadata": {
    "id": "mYsHaqTVFEQZ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭──────────────────────────────────────────────── System Message ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> You are a helpful assistant                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m───────────────────────────────────────────────\u001b[0m\u001b[31m System Message \u001b[0m\u001b[31m────────────────────────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m You are a helpful assistant                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────────── User Message ──────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Giving the following message:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> ---                                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">{{?input}}</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> ---                                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Extract and return a json with the follwoing keys and values:                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> - \"urgency\" as one of `high`, `medium`, `low`                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> - \"sentiment\" as one of `negative`, `neutral`, `positive`                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> - \"categories\" Create a dictionary with categories as keys and boolean values (True/False), where the value     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> indicates whether the category is one of the best matching support category tags from:                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> `emergency_repair_services`, `routine_maintenance_requests`, `quality_and_safety_concerns`,                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> `specialized_cleaning_services`, `general_inquiries`, `sustainability_and_environmental_practices`,             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> `training_and_support_requests`, `cleaning_services_scheduling`, `customer_feedback_and_complaints`,            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> `facility_management_issues`                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Your complete message should be a valid json string that can be read directly and only contain the keys         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────────\u001b[0m\u001b[32m User Message \u001b[0m\u001b[32m─────────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m Giving the following message:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m ---                                                                                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;35m{{?input}}\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m ---                                                                                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Extract and return a json with the follwoing keys and values:                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m - \"urgency\" as one of `high`, `medium`, `low`                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m - \"sentiment\" as one of `negative`, `neutral`, `positive`                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m - \"categories\" Create a dictionary with categories as keys and boolean values (True/False), where the value     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m indicates whether the category is one of the best matching support category tags from:                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m `emergency_repair_services`, `routine_maintenance_requests`, `quality_and_safety_concerns`,                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m `specialized_cleaning_services`, `general_inquiries`, `sustainability_and_environmental_practices`,             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m `training_and_support_requests`, `cleaning_services_scheduling`, `customer_feedback_and_complaints`,            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m `facility_management_issues`                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Your complete message should be a valid json string that can be read directly and only contain the keys         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.        \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Prompt template loaded successfully. Placeholders found are: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'input'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Prompt template loaded successfully. Placeholders found are: \u001b[1m{\u001b[0m\u001b[32m'input'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_prompt_template = \"./facility_prompt.yaml\" # local path to the prompt template or Prompt Repository identifier\n",
    "\n",
    "\n",
    "prompt = load_prompt_template(base_prompt_template) # .escape_curly_brackets() if validation fails.\n",
    "print_prompt_template(prompt)\n",
    "print(f\"Prompt template loaded successfully. Placeholders found are: {prompt.placeholders}\")\n",
    "assert validate_prompt(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wFNUcWAbtgYA",
   "metadata": {
    "id": "wFNUcWAbtgYA"
   },
   "source": [
    "Check if all expected placeholders were found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963zmQ0rCPkT",
   "metadata": {
    "id": "963zmQ0rCPkT"
   },
   "source": [
    "### Validating Local Dataset\n",
    "\n",
    "Your dataset must be a JSON‐serializable list where each element is a dictionary with exactly two keys: **`fields`** and **`answer`**. The **`fields`** value should itself be a dictionary whose keys (e.g. `\"question\"`, `\"hint\"`, `\"term\"`, etc.) are **identical** across every entry and whose values are all strings. The **`answer`** value must also be a string.\n",
    "\n",
    "\n",
    "You can validate your dataset using the `validate_dataset` method.\n",
    "\n",
    "If validation is not passed succesfully this are might be the reasons:\n",
    "\n",
    "\n",
    "| Condition                              | Exception Raised (inner)                                           | Outer Message                    |\n",
    "| -------------------------------------- | ------------------------------------------------------------------ | -------------------------------- |\n",
    "| Non-list top-level                     | N/A                                                                | `Dataset must be a list…`        |\n",
    "| Item not a dict                        | N/A                                                                | `Each item…must be a dictionary` |\n",
    "| Wrong item keys                        | `ValueError(\"Each item must contain 'fields' and 'answer' keys.\")` | `Error in entry i`               |\n",
    "| `\"fields\"` not a dict                  | `ValueError(\"'fields' must be a dictionary.\")`                     | `Error in entry i`               |\n",
    "| Field name mismatch (extra or missing) | `ValueError(\"Unexpected keys…\")` or `ValueError(\"Missing keys…\")`  | `Error in entry i`               |\n",
    "| Non-string field value                 | `ValueError(\"All values in 'fields' must be strings.\")`            | `Error in entry i`               |\n",
    "| Invalid JSON file                      | `ValueError(\"Invalid JSON in file:…\")`                             | N/A                              |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "RMNFj5ZWCyW8",
   "metadata": {
    "id": "RMNFj5ZWCyW8"
   },
   "outputs": [],
   "source": [
    "dataset_local_path=\"./facility-synth-train/facility-train.json\" # local path to the dataset\n",
    "\n",
    "assert validate_dataset(dataset_local_path), \"Dataset not valid\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2nsOfnjEK61",
   "metadata": {
    "id": "b2nsOfnjEK61"
   },
   "source": [
    "### Remaining Config parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab10f2a9",
   "metadata": {
    "id": "ab10f2a9"
   },
   "outputs": [],
   "source": [
    "scenario = \"genai-optimizations\"\n",
    "\n",
    "base_prompt_template_registry = \"evaluate-base:0.0.1\"  # name:version for the template in the registry\n",
    "\n",
    "dataset_secret=\"default\" # secret name in the object store you want to use to store the dataset\n",
    "dataset_remote_path=\"datasets/facility-train.json\" # remote path in the object store to store the dataset\n",
    "\n",
    "reference_model = \"gpt-4o:2024-08-06\"\n",
    "# Dictionary of models to optimize with their corresponding prompt template names under which the optimized prompt should be stored in the registry\n",
    "targets = {\n",
    "    \"gemini-2.5-pro:001\": \"evaluate-base-gemini-2_5-pro:0.0.1\"\n",
    "}\n",
    "\n",
    "# Metric to use for optimization\n",
    "metric = \"JSON_Match\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461f1569",
   "metadata": {
    "id": "461f1569"
   },
   "source": [
    "## Push Local Prompt to Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af015c2a",
   "metadata": {
    "id": "af015c2a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Prompt template evaluate-base already exists. Use <span style=\"color: #808000; text-decoration-color: #808000\">update</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> to update.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Prompt template evaluate-base already exists. Use \u001b[33mupdate\u001b[0m=\u001b[3;92mTrue\u001b[0m to update.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Prompt present in registry under id <span style=\"color: #ffff00; text-decoration-color: #ffff00\">3a9cfc20-f972-4720-8d0e-3ac48f77f391</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Prompt present in registry under id \u001b[93m3a9cfc20-f972-4720-8d0e-3ac48f77f391\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "=== Base Prompt ===\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "=== Base Prompt ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭──────────────────────────────────────────────── System Message ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> You are a helpful assistant                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m───────────────────────────────────────────────\u001b[0m\u001b[31m System Message \u001b[0m\u001b[31m────────────────────────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m You are a helpful assistant                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────────── User Message ──────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Giving the following message:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> ---                                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">{{?input}}</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> ---                                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Extract and return a json with the follwoing keys and values:                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> - \"urgency\" as one of `high`, `medium`, `low`                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> - \"sentiment\" as one of `negative`, `neutral`, `positive`                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> - \"categories\" Create a dictionary with categories as keys and boolean values (True/False), where the value     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> indicates whether the category is one of the best matching support category tags from:                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> `emergency_repair_services`, `routine_maintenance_requests`, `quality_and_safety_concerns`,                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> `specialized_cleaning_services`, `general_inquiries`, `sustainability_and_environmental_practices`,             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> `training_and_support_requests`, `cleaning_services_scheduling`, `customer_feedback_and_complaints`,            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> `facility_management_issues`                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Your complete message should be a valid json string that can be read directly and only contain the keys         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────────\u001b[0m\u001b[32m User Message \u001b[0m\u001b[32m─────────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m Giving the following message:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m ---                                                                                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;35m{{?input}}\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m ---                                                                                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Extract and return a json with the follwoing keys and values:                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m - \"urgency\" as one of `high`, `medium`, `low`                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m - \"sentiment\" as one of `negative`, `neutral`, `positive`                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m - \"categories\" Create a dictionary with categories as keys and boolean values (True/False), where the value     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m indicates whether the category is one of the best matching support category tags from:                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m `emergency_repair_services`, `routine_maintenance_requests`, `quality_and_safety_concerns`,                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m `specialized_cleaning_services`, `general_inquiries`, `sustainability_and_environmental_practices`,             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m `training_and_support_requests`, `cleaning_services_scheduling`, `customer_feedback_and_complaints`,            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m `facility_management_issues`                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Your complete message should be a valid json string that can be read directly and only contain the keys         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.        \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_template = load_prompt_template(base_prompt_template)\n",
    "prompt_template_name_registry, _, prompt_template_version = base_prompt_template_registry.partition(\":\")\n",
    "prompt = push_prompt_template(prompt_template=base_template,\n",
    "                              prompt_template_name_registry=prompt_template_name_registry,\n",
    "                              prompt_template_version=prompt_template_version,\n",
    "                              scenario=scenario,\n",
    "                              update=False\n",
    ")\n",
    "\n",
    "print(f\"Prompt present in registry under id {prompt['id']}\")\n",
    "\n",
    "print('\\n\\n=== Base Prompt ===')\n",
    "print_prompt_template(prompt[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df4d0a8",
   "metadata": {
    "id": "8df4d0a8"
   },
   "source": [
    "## Push Local Dataset to Object Store and Create Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46937ef",
   "metadata": {
    "id": "f46937ef"
   },
   "outputs": [],
   "source": [
    "artifact, dataset_path = upload_dataset(\n",
    "    secret=dataset_secret,\n",
    "    local_path=dataset_local_path,\n",
    "    remote_path=dataset_remote_path,\n",
    "    expected_keys=base_template.placeholders,\n",
    "    scenario=scenario,\n",
    "    overwrite=True,\n",
    "    allow_bucket_root=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset uploaded to {artifact.url}/{dataset_path} -> Artifact ID: {artifact.id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4ec0c5",
   "metadata": {
    "id": "ab4ec0c5"
   },
   "source": [
    "## Create Prompt Optimizer Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4PuS58nc8i7w",
   "metadata": {
    "id": "4PuS58nc8i7w"
   },
   "outputs": [],
   "source": [
    "configuration_id = create_config(metric=metric,\n",
    "                                 reference_model=reference_model,\n",
    "                                 targets=targets,\n",
    "                                 dataset_path=dataset_path,\n",
    "                                 scenario=scenario,\n",
    "                                 prompt=prompt\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dde0e00",
   "metadata": {
    "id": "5dde0e00"
   },
   "source": [
    "## Start Prompt Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa02b617",
   "metadata": {
    "id": "aa02b617"
   },
   "outputs": [],
   "source": [
    "response = client.ai_core_client.execution.create(\n",
    "    configuration_id = configuration_id, # Change this value.\n",
    "    resource_group = \"default\"\n",
    ")\n",
    "\n",
    "execution_id = response.id\n",
    "print('Execution started with ID:', execution_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aSkihvDXKcAv",
   "metadata": {
    "id": "aSkihvDXKcAv"
   },
   "source": [
    "## Check Execution Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee23e5",
   "metadata": {
    "id": "96ee23e5"
   },
   "outputs": [],
   "source": [
    "result = fetch_results(execution_id)\n",
    "print_result(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Pd3wsKls4OS5"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
